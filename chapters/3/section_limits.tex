\subsection{Discovery and upper limits}
\label{sec:limits}

After the number of signal and background events in the signal region have been determined, along with all statistical and systematic uncertainties, the final step of the analysis is to quantify the amount of signal that is present in the data. For the mono-$Z$ analysis, a signal would manifest itself as an excess of data in the $E_\text{T}^\text{miss}$ distribution compared to the predicted background. 

In ATLAS, frequentist methods \cite{Cowan:2010js}, \cite{freqLimitRecs} have been adopted in order to quantify the signal strength we observe. The first test to perform is to calculate the p-value for the null hypothesis. This gives a direct measure of how compatible the dataset is with the $\mu=0$ (background only) hypothesis, where $\mu$ is the signal strength. In order to do this, one must first construct a likelihood function for the parameter of interest, $\mu$, in terms of the other parameters of the analysis.  This function is formed from the product of several probability distributions, including the Poisson distributions for the number of background events observed, the total number of events observed, and the distributions for all nuisance parameters along with their errors. This likelihood is then used in the definition of the frequentist profile likelihood ratio:

\begin{equation}
\lambda(\mu) = \frac{L(\mu, \hat{\hat{\vec{\theta}}})}{L(\hat{\mu}, \hat{\vec{\theta}})} 
\end{equation}

\noindent $\vec{\theta}$ are the nuisance parameters of the analysis. The denominator is simply the maximum likelihood function, and the numerator is the profiled likelihood for $\mu$. This ratio is always between 0 and 1. If $\mu$ and $\hat{\mu}$ are close in value, then $\lambda(\mu)$ will be close to 1, and if $\mu$ is much different from $\hat{\mu}$, then $\lambda(\mu)$ will be smaller and hence represent greater incompatibility between $\mu$ and $\hat{\mu}$. This likelihood ratio is used in the test statistic constructed to calculate the p-value for the null hypothesis. This test statistic,  $q_0$, depends on $\lambda(\mu)$ and is defined so that larger values correspond to greater incompatibility between the data and the $\mu=0$ hypothesis. Therefore, the p-value, $p_0$, is defined to be the integral over the distribution $f(q_0 | \mu=0)$ from the observed value (obtained using the $\hat{\mu}$ from the data) for $q_0$ to infinity. Hence, smaller p-values correspond to more incompatibility between the data and the null hypothesis.

At this point it is important to note that, although $f(q_0 | 0)$ can be determined from pseudo-experiments, as explored in my 2014 work term \cite{McLean}, the distribution is exactly predicted in the large-statistics limit using so-called \textit{asymptotic} formulas. Asymptotics are widely used in ATLAS; the test statistics are defined such that asymptotics can apply. They predict the closed form of $f(q_0 | 0)$ and hence also the closed form of $p_0$. The same applies to the test statistics used for setting upper limits on the signal strength, to be discussed next. 

If $p_0$ is sufficiently small, then evidence for a discovery can be claimed. Depending on the value of $p_0$, the level of evidence can be expressed in terms of $\sigma$. If $p_0$ is large, however, then an upper limit needs to be set on $\mu$. This is done using the $CL_s$ method \cite{CLsInfo}. The program that is commonly used to calculate limits is called $\texttt{HistFitter}$ \cite{Baak:2014wma}. The methodology is similar as for calculating $p_0$. A test statistic is defined called $\tilde{q}_\mu$ that depends on a modified profile likelihood ratio $\tilde{\lambda}(\mu)$. Now the test statistic $\tilde{q}_\mu$ tests $\hat{\mu}$ against various hypothetical values for $\mu$. Then the p-value $p_\mu'$ (specific to the $CL_s$ method) is defined in a way so that sensitivity is preserved for $s \ll b$, unlike in the $CL_{s+b}$ method. Once again, the distribution of $\tilde{q}_\mu$ and hence $p_\mu'$ are determined from asymptotics (or toys) in \texttt{HistFitter}. The observed upper limit on $\mu$ is then defined as being the value of $\mu$ for which $p_\mu = 0.05$. This is the observed upper limit on $\mu$ at the 95\% confidence level.

The expected upper limit is also calculated using the $CL_s$ method. To do this manually, one would generate several toy experimental datasets, along with toy Monte Carlos for each of those datasets, assuming $\mu=0$. The above analysis would be repeated for each pseudo-experiment and a distribution of upper limits would be obtained. The expected limit is the median of the distribution, and the $1\sigma$ and $2\sigma$ bands would are obtained from the width. When appropriate, asymptotics can be used instead. This is what is done in \texttt{HistFitter}.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{Figures/limits.pdf}
\caption[Mass limit plot example for vector-mediated simplified model]{Mass limit plot example for vector-mediated simplified model \cite{Boveia:2016mrp}.}
\label{fig:limits}
\end{figure}

The limits on the signal strength are calculated for the different models and mass points being studied, and can be converted into limits on other quantities, such as the dark matter/mediator masses and dark matter production cross sections. Figure \ref{fig:limits} illustrates an example of what a mass limit plot for the vector-mediated simplified model may look like, where limits on $m_\chi$ are plotted for various mediator masses. The area under the curve would represent masses that are excluded at the 95\% confidence level. There are also methods to plotting the relic density limit seen in Figure \ref{fig:limits} and to convert into limits on $\chi$-nucleon scattering cross sections, allowing for comparison with exclusions made by other types of experiments \cite{Boveia:2016mrp}. This is the major goal of the analysis if a discovery is not made.

Work is now being done to understand the details involved in using \texttt{HistFitter} to calculate limits, including what inputs are needed and the machinery behind the tool. Calculating limits is an important part of the analysis and one of the immediate goals is to gain confidence in using \texttt{HistFitter}. During this pursuit it should be possible to run with some preliminary error estimates and obtain prospective limits for the 2015 dataset before the full analysis is ready. \texttt{HistFitter} will also be used to set limits on the 2015-2017 dataset and it will be useful to invest time now into understanding how it works. My previous work on calculating limits during my 2014 co-op work term is also helpful in learning \texttt{HistFitter}.