\startchapter{The Mono-$Z(\ell\ell)$ Search}
\label{chapter:prevWork}

% --------------------------------------------------------------------------------------
\section{Analysis Overview}

There are several important aspects of the mono-$Z$ search. One of the the first steps of the analysis is to optimize the event selection for the specific signal being considered in the search. A \textit{signal region} must be chosen using some metric that optimizes the amount of signal compared to background. Background events are caused by SM processes that produce the same signature as the dark matter signal. Ideally such processes should be as suppressed as possible in the signal region. Event selections are optimized using Monte Carlo (MC) simulated events for signal and backgrounds. ATLAS MC are sophisticated and include effects from the detector, such as energy resolution. In general, events are selected in order to isolate a $e^+e^-$ or $\mu^+\mu^-$ pair that have an invariant mass close to the $Z$ and are recoiling against a sizeable $E_{T}^{\text{miss}}$ vector. The most important kinematic variables are identified and calculated using reconstructed objects as measured in the ATLAS detector (approximate in MC). Additional selection requirements are used to reduce background contributions while attempting to preserve signal. Two signal regions are used in the mono-$Z$ analysis, one where $e^+e^-$ events are selected and the other where $\mu^+\mu^-$ events are selected.

Another crucial part of the analysis is in-situ background estimation. Once a signal region has been defined, data can then be used to estimate the dominant backgrounds in that region. When possible, it is always preferable to use data instead of MC estimations for backgrounds. 

- major backgrounds (pie chart?)\\
- systematic errors\\
- limit setting on MET distribution\\
- mention results so far for ICHEP 2016 and EPS 2017, and for DM summary paper\\
- mention full Run 2 dataset prospects?\\

% --------------------------------------------------------------------------------------
\section{Truth Studies} 

- explain difference between reconstructed and truth samples\\
- motivation: at generator level we ignore detector effects; also sometimes cannot have access to many reconstructed samples, we can produce them ourselves\\
- MonoZTruthUVic framework for applying truth-level analysis cuts\\

% -------------------------------------------
\subsection{Theory Systematics on the Signal Acceptance}
- QCD renormalization/factorization scale systematics\\
- parton showering systematics\\
- mention possibility to use weights instead\\

% --------------------------------------------------------------------------------------
\section{Estimation of the $Z$+jets Background}

% -------------------------------------------
\subsection{ABCD Method}

- overview of the method\\
- challenges (correlations, low stats, large systematics)\\
- mention methodology used for EPS (?)\\

% -------------------------------------------
\subsection{$\gamma$+jets Technique}

- overview of the method\\
- challenges (trial and error with reweighting in 1D, 2D, or 2x1D; smearing, resolution of the Z better than the photon)\\

% --------------------------------------------------------------------------------------
\section{Dark Matter Limit Setting}

- some theory of hypothesis testing (binned likelihoods, p-values, discovery vs upper limits)\\
- MonoZLimitsUVic framework for setting limits\\
- show dmA and dmV results from ICHEP and EPS\\
- mention rescaled NLO limits for DM summary paper (?)\\
- show 2HDMa results for DM summary paper\\

% -------------------------------------------
\subsection{Mass Point Emulation}

- create a finer grid of points without using reconstructed samples\\
- studies done to show that it's possible to scale from dmA -> dmA in the on-shell region for a fixed mediator mass\\
- studies also done to show it's possible to scale dmA -> dmV\\

% --------------------------------------------------------------------------------------
\section{Analysis Software}
- mention efforts to update/improve our code (?)